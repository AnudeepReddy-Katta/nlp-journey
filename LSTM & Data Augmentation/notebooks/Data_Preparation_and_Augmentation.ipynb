{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Preparation and Augmentation.ipynb",
      "provenance": [],
      "mount_file_id": "10le13tEW0-rcb7Tf_GHWhM4Kxc1eYAPP",
      "authorship_tag": "ABX9TyOljvXjMlUanbrgQMNN96uH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnudeepReddy-Katta/SentimentAnalysis/blob/main/notebooks/Data_Preparation_and_Augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bHP2OLrVFWr",
        "outputId": "d895cab1-9bbe-416e-d36a-9e362838baf9"
      },
      "source": [
        "!pip install pip install googletrans==3.1.0a0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (19.3.1)\n",
            "Requirement already satisfied: install in /usr/local/lib/python3.7/dist-packages (1.3.4)\n",
            "Collecting googletrans==3.1.0a0\n",
            "  Downloading https://files.pythonhosted.org/packages/19/3d/4e3a1609bf52f2f7b00436cc751eb977e27040665dde2bd57e7152989672/googletrans-3.1.0a0.tar.gz\n",
            "Collecting httpx==0.13.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/b4/698b284c6aed4d7c2b4fe3ba5df1fcf6093612423797e76fbb24890dd22f/httpx-0.13.3-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (3.0.4)\n",
            "Requirement already satisfied: idna==2.* in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2.10)\n",
            "Collecting sniffio\n",
            "  Downloading https://files.pythonhosted.org/packages/52/b0/7b2e028b63d092804b6794595871f936aafa5e9322dcaaad50ebf67445b3/sniffio-1.2.0-py3-none-any.whl\n",
            "Collecting rfc3986<2,>=1.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c4/e5/63ca2c4edf4e00657584608bee1001302bbf8c5f569340b78304f2f446cb/rfc3986-1.5.0-py2.py3-none-any.whl\n",
            "Collecting httpcore==0.9.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/d5/e4ff9318693ac6101a2095e580908b591838c6f33df8d3ee8dd953ba96a8/httpcore-0.9.1-py3-none-any.whl (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 4.6MB/s \n",
            "\u001b[?25hCollecting hstspreload\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/50/606213e12fb49c5eb667df0936223dcaf461f94e215ea60244b2b1e9b039/hstspreload-2020.12.22-py3-none-any.whl (994kB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2020.12.5)\n",
            "Collecting h2==3.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/de/da019bcc539eeab02f6d45836f23858ac467f584bfec7a526ef200242afe/h2-3.2.0-py2.py3-none-any.whl (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.2MB/s \n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/fd/3dad730b0f95e78aeeb742f96fa7bbecbdd56a58e405d3da440d5bfb90c6/h11-0.9.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.4MB/s \n",
            "\u001b[?25hCollecting hpack<4,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8a/cc/e53517f4a1e13f74776ca93271caef378dadec14d71c61c949d759d3db69/hpack-3.0.0-py2.py3-none-any.whl\n",
            "Collecting hyperframe<6,>=5.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/19/0c/bf88182bcb5dce3094e2f3e4fe20db28a9928cb7bd5b08024030e4b140db/hyperframe-5.2.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-3.1.0a0-cp37-none-any.whl size=16368 sha256=df82490b553d0473b45971e2a141edf6b83dfb1e87be55dfb48e3389d153c956\n",
            "  Stored in directory: /root/.cache/pip/wheels/27/7a/a0/aff3babbb775549ce6813cb8fa7ff3c0848c4dc62c20f8fdac\n",
            "Successfully built googletrans\n",
            "Installing collected packages: sniffio, rfc3986, hpack, hyperframe, h2, h11, httpcore, hstspreload, httpx, googletrans\n",
            "Successfully installed googletrans-3.1.0a0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2020.12.22 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 rfc3986-1.5.0 sniffio-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwMHEcmBSTiM"
      },
      "source": [
        "import pandas as pd\n",
        "datasetSentences = pd.read_csv((\"/content/drive/MyDrive/NLP/datasetSentences.txt\"), sep=\"\\t\", skiprows=[0], names=['sentence_index','sentence'])\n",
        "sentiment_labels = pd.read_csv((\"/content/drive/MyDrive/NLP/sentiment_labels.txt\"), sep=\"|\", skiprows=[0], names=['phrase_id','sentiment_values'])\n",
        "dictionary = pd.read_csv((\"/content/drive/MyDrive/NLP/dictionary.txt\"), sep=\"|\", names=['phrase','phrase_id'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1NKJpEUSUXB"
      },
      "source": [
        "def pre_process_sentences(string):\n",
        "  string=string.replace('-LRB-','(')\n",
        "  string=string.replace('-RRB-',')')\n",
        "  string=string.replace('Â', '')\n",
        "  string=string.replace('Ã©', 'e')\n",
        "  string=string.replace('Ã¨', 'e')\n",
        "  string=string.replace('Ã¯', 'i')\n",
        "  string=string.replace('Ã³', 'o')\n",
        "  string=string.replace('Ã´', 'o')\n",
        "  string=string.replace('Ã¶', 'o')\n",
        "  string=string.replace('Ã±', 'n')\n",
        "  string=string.replace('Ã¡', 'a')\n",
        "  string=string.replace('Ã¢', 'a')\n",
        "  string=string.replace('Ã£', 'a')\n",
        "  string=string.replace('\\xc3\\x83\\xc2\\xa0', 'a')\n",
        "  string=string.replace('Ã¼', 'u')\n",
        "  string=string.replace('Ã»', 'u')\n",
        "  string=string.replace('Ã§', 'c')\n",
        "  string=string.replace('Ã¦', 'ae')\n",
        "  string=string.replace('Ã­', 'i')\n",
        "  string=string.replace('\\xa0', ' ')\n",
        "  string=string.replace('\\xc2', '')\n",
        "  return string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVmq6ODaSXKz"
      },
      "source": [
        "datasetSentences['sentence'] = datasetSentences['sentence'].apply(pre_process_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J5zAIjmSZQY"
      },
      "source": [
        "def pre_process_phrases(string):\n",
        "    string=string.replace('é','e')\n",
        "    string=string.replace('è','e')\n",
        "    string=string.replace('ï','i')\n",
        "    string=string.replace('í','i')\n",
        "    string=string.replace('ó','o')\n",
        "    string=string.replace('ô','o')\n",
        "    string=string.replace('ö','o')\n",
        "    string=string.replace('á','a')\n",
        "    string=string.replace('â','a')\n",
        "    string=string.replace('ã','a')\n",
        "    string=string.replace('à','a')\n",
        "    string=string.replace('ü','u')\n",
        "    string=string.replace('û','u')\n",
        "    string=string.replace('ñ','n')\n",
        "    string=string.replace('ç','c')\n",
        "    string=string.replace('æ','ae')\n",
        "    string=string.replace('\\xa0', ' ')\n",
        "    string=string.replace('\\xc2', '')    \n",
        "    return string "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCIc56tlSa_0"
      },
      "source": [
        "dictionary['phrase'] = dictionary['phrase'].apply(pre_process_phrases)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "NOdOwdD6Sckw",
        "outputId": "3a769a65-cab4-4c94-d1cd-6c90fe0c6dd8"
      },
      "source": [
        "df1 = pd.merge(sentiment_labels,dictionary,on='phrase_id')\n",
        "df1.drop(columns=['phrase_id'],inplace = True)\n",
        "df1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment_values</th>\n",
              "      <th>phrase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.50000</td>\n",
              "      <td>!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.50000</td>\n",
              "      <td>'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.44444</td>\n",
              "      <td>' (</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.50000</td>\n",
              "      <td>' ( the cockettes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.42708</td>\n",
              "      <td>' ( the cockettes )</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment_values               phrase\n",
              "0           0.50000                    !\n",
              "1           0.50000                    '\n",
              "2           0.44444                  ' (\n",
              "3           0.50000    ' ( the cockettes\n",
              "4           0.42708  ' ( the cockettes )"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "WeFcngxnSeyF",
        "outputId": "6cb68e61-a3e1-41a4-db9a-173f37cdb328"
      },
      "source": [
        "df2 = pd.merge(df1,datasetSentences,left_on='phrase',right_on='sentence')\n",
        "df2.drop(columns = ['phrase','sentence_index'],inplace = True)\n",
        "df2.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment_values</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.013889</td>\n",
              "      <td>... a bland murder-on-campus yawner .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.263890</td>\n",
              "      <td>... a hollow joke told by a cinematic gymnast ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.472220</td>\n",
              "      <td>... the picture 's cleverness is ironically mu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.875000</td>\n",
              "      <td>classic cinema served up with heart and humor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.319440</td>\n",
              "      <td>entertaining enough , but nothing new</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sentiment_values                                           sentence\n",
              "0          0.013889              ... a bland murder-on-campus yawner .\n",
              "1          0.263890  ... a hollow joke told by a cinematic gymnast ...\n",
              "2          0.472220  ... the picture 's cleverness is ironically mu...\n",
              "3          0.875000      classic cinema served up with heart and humor\n",
              "4          0.319440              entertaining enough , but nothing new"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-6b6vOpSnhX"
      },
      "source": [
        "df2.loc[(df2['sentiment_values']>=0) & (df2['sentiment_values']<=0.2),'label']=0\n",
        "df2.loc[(df2['sentiment_values']>0.2) & (df2['sentiment_values']<=0.4),'label']=1\n",
        "df2.loc[(df2['sentiment_values']>0.4) & (df2['sentiment_values']<=0.6),'label']=2\n",
        "df2.loc[(df2['sentiment_values']>0.6) & (df2['sentiment_values']<=0.8),'label']=3\n",
        "df2.loc[(df2['sentiment_values']>0.8) & (df2['sentiment_values']<=1),'label']=4\n",
        "df2.drop(columns = ['sentiment_values'],inplace = True)\n",
        "df2.rename(columns={'label':'sentiment_values'},inplace = True)\n",
        "df2['sentiment_values'] = df2['sentiment_values'].astype('int')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQIpO0j0Syrn",
        "outputId": "294ef150-ebe3-40db-b5ff-5e9d9478a272"
      },
      "source": [
        "df2['sentiment_values'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    3140\n",
              "3    3111\n",
              "2    2242\n",
              "4    1851\n",
              "0    1510\n",
              "Name: sentiment_values, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1M7nzbITWjb5",
        "outputId": "90a01aaf-131b-45b7-e814-b58079afc781"
      },
      "source": [
        "len(df2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11854"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTTjIzt-aeEB"
      },
      "source": [
        "def random_deletion(sentence, p=0.5): \n",
        "    words = sentence.split()\n",
        "    if len(words) == 1: # return if single word\n",
        "        return words[0]\n",
        "    remaining = list(filter(lambda x: random.uniform(0,1) > p,words)) \n",
        "    if len(remaining) == 0: # if not left, sample a random word\n",
        "        return [random.choice(words)][0]\n",
        "    else:\n",
        "        return ' '.join(remaining)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrPlOdi4aeIr"
      },
      "source": [
        "def random_swap(sentence, n=5): \n",
        "    sentence = sentence.split()\n",
        "    length = range(len(sentence)) \n",
        "    for _ in range(n):\n",
        "        idx1, idx2 = random.sample(length, 2)\n",
        "        sentence[idx1], sentence[idx2] = sentence[idx2], sentence[idx1] \n",
        "    return ' '.join(sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZk_jBu-gSna"
      },
      "source": [
        "import random\n",
        "import googletrans\n",
        "from  googletrans import Translator\n",
        "\n",
        "def back_translate(sentence):\n",
        "  sentence = sentence.split()\n",
        "  translator = Translator()\n",
        "  available_langs = list(googletrans.LANGUAGES.keys()) \n",
        "  trans_lang = random.choice(available_langs) \n",
        "\n",
        "  translations = translator.translate(sentence, dest=trans_lang) \n",
        "  t_text = [t.text for t in translations]\n",
        "\n",
        "  translations_en_random = translator.translate(t_text, src=trans_lang, dest='en') \n",
        "  en_text = [t.text for t in translations_en_random]\n",
        "  return ' '.join(en_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p31MJGjVhBeH"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from random import shuffle\n",
        "def augment_text(df,samples,label,samples_back_translate=0.1,\n",
        "                 samples_random_swap=.45,samples_random_deletion=.45):\n",
        "    new_text=[]\n",
        "    \n",
        "    ##selecting a class samples\n",
        "    df_n=df[df.sentiment_values==label].reset_index(drop=True)\n",
        "\n",
        "    ## data augmentation loops\n",
        "    for i in tqdm(np.random.randint(0,len(df_n),int(samples_back_translate*samples))):\n",
        "        \n",
        "            text = df_n.iloc[i]['sentence']\n",
        "            augmented_text = back_translate(text)\n",
        "            new_text.append(augmented_text)\n",
        "    \n",
        "    for i in tqdm(np.random.randint(0,len(df_n),int(samples_random_swap*samples))):\n",
        "        \n",
        "            text = df_n.iloc[i]['sentence']\n",
        "            augmented_text = random_swap(text)\n",
        "            new_text.append(augmented_text)\n",
        "\n",
        "    for i in tqdm(np.random.randint(0,len(df_n),int(samples_random_deletion*samples))):\n",
        "        \n",
        "            text = df_n.iloc[i]['sentence']\n",
        "            augmented_text = random_deletion(text)\n",
        "            new_text.append(augmented_text)\n",
        "    \n",
        "    ## dataframe\n",
        "    new=pd.DataFrame({'sentence':new_text,'sentiment_values':label})\n",
        "    return new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3nX7f2iSTGd"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(df2, test_size=0.2, random_state=42, stratify=df2['sentiment_values']) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nff3pL3Avwqr",
        "outputId": "7c6cf28a-38cd-4b42-f72a-cfeefcc70a6f"
      },
      "source": [
        "df_0 = augment_text(train,1300,0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 130/130 [29:29<00:00, 13.61s/it]\n",
            "100%|██████████| 585/585 [00:00<00:00, 5049.56it/s]\n",
            "100%|██████████| 585/585 [00:00<00:00, 6545.80it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA9rydaaOaEh"
      },
      "source": [
        "df_0.to_csv('/content/drive/MyDrive/NLP/df_0.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oo93uOnyvxW7",
        "outputId": "ddf29f27-b9b1-4fbc-ab41-c1f2369cb311"
      },
      "source": [
        "df_2 = augment_text(train,700,2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 70/70 [15:48<00:00, 13.55s/it]\n",
            "100%|██████████| 315/315 [00:00<00:00, 5690.88it/s]\n",
            "100%|██████████| 315/315 [00:00<00:00, 6409.39it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBx84hi1PEzw"
      },
      "source": [
        "df_2.to_csv('/content/drive/MyDrive/NLP/df_2.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUK0EUqwwBfz",
        "outputId": "f80bf23b-f6ce-4114-fb87-fd56325b9239"
      },
      "source": [
        "df_4 = augment_text(train,1000,4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [20:50<00:00, 12.51s/it]\n",
            "100%|██████████| 450/450 [00:00<00:00, 5722.54it/s]\n",
            "100%|██████████| 450/450 [00:00<00:00, 6106.63it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnPux7gHTZTN"
      },
      "source": [
        "df_4.to_csv('/content/drive/MyDrive/NLP/df_4.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E0iQ1Mp6WGeW"
      },
      "source": [
        "train.to_csv('/content/drive/MyDrive/NLP/train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6ObFDr0nkTX"
      },
      "source": [
        "test.to_csv('/content/drive/MyDrive/NLP/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxnDhxMxpr3H"
      },
      "source": [
        "train = train.reset_index()\n",
        "train.drop(columns='index',inplace=True)\n",
        "train = train.append(df_0).reset_index(drop=True)\n",
        "train = train.append(df_2).reset_index(drop=True)\n",
        "train = train.append(df_4).reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cBcT2GOqxTb"
      },
      "source": [
        "train.to_csv('/content/drive/MyDrive/NLP/train_aug.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNAQLWUetwh1"
      },
      "source": [
        "test =test.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_lpeH2Urv9t"
      },
      "source": [
        "test.to_csv('/content/drive/MyDrive/NLP/test.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qY-bnan2t_Ii"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}